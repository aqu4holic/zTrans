{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "seed = 18022004\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix: str = 'data'\n",
    "repo_prefix: str = f'{data_prefix}/repos'\n",
    "\n",
    "# data_name_template: str = '500_{}_sample_dataset.parquet'\n",
    "# data_types = ['log', 'test', 'others']\n",
    "\n",
    "# sampled_data_name: Dict[str, str] = {data_type: data_name_template.format(data_type) for data_type in data_types}\n",
    "\n",
    "# log_df: pd.DataFrame = pd.read_parquet(f'{data_prefix}/{sampled_data_name['log']}', engine = 'pyarrow')\n",
    "# test_df: pd.DataFrame = pd.read_parquet(f'{data_prefix}/{sampled_data_name['test']}', engine = 'pyarrow')\n",
    "# others_df: pd.DataFrame = pd.read_parquet(f'{data_prefix}/{sampled_data_name['others']}', engine = 'pyarrow')\n",
    "\n",
    "data_name = 'migration_others_method_no_code.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df: pd.DataFrame = pd.read_parquet(f'{data_prefix}/{data_name}', engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "import tree_sitter_java as tsjava\n",
    "import difflib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the parser and set the Java language\n",
    "JAVA_LANGUAGE = Language(tsjava.language())\n",
    "parser = Parser(JAVA_LANGUAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'fromLib', 'toLib', 'repoName', 'repoOwner', 'repoSplitName',\n",
       "       'prevCommit', 'startCommit', 'endCommit', 'fileName',\n",
       "       'startCommitChanges', 'endCommitChanges', 'total_methods_before',\n",
       "       'total_methods_after', 'class_before', 'class_after',\n",
       "       'method_before_name', 'method_after_name', 'method_before',\n",
       "       'method_after', 'method_diff', 'method_before_modifiers',\n",
       "       'method_after_modifiers', 'method_before_return_type',\n",
       "       'method_after_return_type', 'method_before_parameters',\n",
       "       'method_after_parameters', 'method_before_signature',\n",
       "       'method_after_signature', 'method_before_signature_no_mod',\n",
       "       'method_after_signature_no_mod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_df.iloc[154550]['method_after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, indent = 0):\n",
    "    \"\"\"\n",
    "    Recursively prints the tree structure of a tree-sitter node.\n",
    "\n",
    "    :param node: The current tree-sitter node.\n",
    "    :param source_code: The source code being parsed, as bytes.\n",
    "    :param indent: The current indentation level for pretty-printing.\n",
    "    \"\"\"\n",
    "    # Extract node information\n",
    "    node_type = node.type\n",
    "    node_text = node.text.decode('utf-8')\n",
    "\n",
    "    node_text = [line for line in node_text.split('\\n') if line.strip()]\n",
    "\n",
    "    # Print the node details with indentation\n",
    "    print(f\"{'  ' * indent}{node_type}: '{node_text}'\")\n",
    "\n",
    "    # Recursively print child nodes\n",
    "    for child in node.children:\n",
    "        print_tree(child, indent + 1)\n",
    "\n",
    "def extract_method_details(node, class_name, source_code):\n",
    "    method_details = {\n",
    "        'class_name': class_name,\n",
    "        'body': '',\n",
    "        'modifiers': '',\n",
    "        'return_type': '',\n",
    "        'name': '',\n",
    "        'parameters': '',\n",
    "        'signature': '',\n",
    "    }\n",
    "\n",
    "    start_byte, end_byte = node.start_byte, node.end_byte\n",
    "    method_details['body'] = source_code[start_byte:end_byte].decode('utf-8', errors = 'replace')\n",
    "\n",
    "    for child in node.children:\n",
    "        if (child.type == 'modifiers'):\n",
    "            method_details['modifiers'] = ' '.join([modifier.text.decode('utf-8') for modifier in child.children])\n",
    "        elif ('type' in child.type):  # Return type\n",
    "            method_details['return_type'] = child.text.decode('utf-8')\n",
    "        elif (child.type == 'identifier'):  # Method name\n",
    "            method_details['name'] = child.text.decode('utf-8')\n",
    "        elif (child.type.endswith('parameters')):  # Parameter list\n",
    "            param_string = ', '.join([param.text.decode('utf-8') for param in child.children if param.type.endswith('parameter')])\n",
    "            method_details['parameters'] = param_string\n",
    "\n",
    "    method_details['signature'] = f'{method_details[\"modifiers\"]} {method_details[\"return_type\"]} {method_details[\"name\"]}({method_details[\"parameters\"]})'\n",
    "    method_details['signature_no_mod'] = f'{method_details[\"return_type\"]} {method_details[\"name\"]}({method_details[\"parameters\"]})'\n",
    "\n",
    "    return method_details\n",
    "\n",
    "def extract_methods_with_body(java_code):\n",
    "    # print('java_code :',java_code)\n",
    "\n",
    "    def has_errors(node):\n",
    "        if node.type == 'ERROR':\n",
    "            print(node.text.decode('utf-8'))\n",
    "            return True\n",
    "        return any(has_errors(child) for child in node.children)\n",
    "\n",
    "    def dfs_find_methods(node: Any, encoded_code, class_context: List[str] = None, ) -> List[Dict[str, Any]]:\n",
    "        '''Perform DFS to find all method_declaration nodes and their enclosing class hierarchy.'''\n",
    "        if class_context is None:\n",
    "            class_context = []\n",
    "\n",
    "        method_details = []\n",
    "\n",
    "        # If the node is a class, update the class context\n",
    "        if node.type == 'class_declaration':\n",
    "            class_name = None\n",
    "            for child in node.children:\n",
    "                if child.type == 'identifier':  # Class name\n",
    "                    class_name = child.text.decode('utf-8')\n",
    "                    break\n",
    "            if class_name:\n",
    "                class_context.append(class_name)\n",
    "\n",
    "        # If the node is a method, extract its details with the full class hierarchy\n",
    "        if node.type == 'method_declaration':\n",
    "            full_class_name = '.'.join(class_context)  # Concatenate class names to show the hierarchy\n",
    "            method_details.append(extract_method_details(node = node, class_name = full_class_name, source_code = encoded_code,))\n",
    "\n",
    "        # Recursively process all children\n",
    "        for child in node.children:\n",
    "            method_details.extend(dfs_find_methods(child, encoded_code, class_context[:]))  # Pass a copy of class context\n",
    "\n",
    "        # If the node is a class, pop the class name after processing its children\n",
    "        if node.type == 'class_declaration' and class_context:\n",
    "            class_context.pop()\n",
    "\n",
    "        return method_details\n",
    "\n",
    "    try:\n",
    "        encoded_code = java_code.encode('utf-8')\n",
    "        tree = parser.parse(encoded_code)\n",
    "        root_node = tree.root_node\n",
    "\n",
    "        if (has_errors(root_node)):\n",
    "            raise Exception('Parsing errors found in the code')\n",
    "\n",
    "        return dfs_find_methods(root_node, encoded_code)\n",
    "    except Exception as e:\n",
    "        print('Loi :' ,e)\n",
    "        return None\n",
    "\n",
    "# Function to remove comments\n",
    "def remove_comments(java_code: str) -> str:\n",
    "    # Parse the code\n",
    "    tree = parser.parse(java_code.encode('utf-8'))\n",
    "    root_node = tree.root_node\n",
    "\n",
    "    # Gather ranges of comment nodes\n",
    "    comment_ranges = []\n",
    "    def visit_node(node):\n",
    "        if node.type in {'line_comment', 'block_comment'}:\n",
    "            comment_ranges.append((node.start_byte, node.end_byte, node.type))\n",
    "        for child in node.children:\n",
    "            visit_node(child)\n",
    "\n",
    "    visit_node(root_node)\n",
    "\n",
    "    # Remove comments by excluding their byte ranges\n",
    "    result_code = bytearray(java_code, 'utf-8')\n",
    "    for start, end, comment_type in reversed(comment_ranges):  # Reverse to avoid shifting indices\n",
    "        if comment_type == 'block_comment':\n",
    "            # Replace block comment with spaces\n",
    "            result_code[start:end] = b' ' * (end - start + 1)\n",
    "            # del result_code[start:end]\n",
    "        else:\n",
    "            # Remove line comments entirely\n",
    "            result_code[start:end] = b' ' * (end - start + 1)\n",
    "        # del result_code[start:end]\n",
    "\n",
    "    return result_code.decode('utf-8').strip()\n",
    "\n",
    "def diff_methods(methods_start, methods_end):\n",
    "    '''\n",
    "    Compare methods based on their full dictionaries (e.g., name, signature, body).\n",
    "    '''\n",
    "    # Normalize methods for comparison\n",
    "    def normalize_methods(methods):\n",
    "        res = []\n",
    "        for method in methods:\n",
    "            sub_method = {}\n",
    "\n",
    "            sub_method['class_name'] = method['class_name'].strip()\n",
    "            sub_method['name'] = method['name'].strip()\n",
    "            sub_method['body'] = method['body'].strip()\n",
    "            sub_method['modifiers'] = method['modifiers'].strip()\n",
    "            sub_method['return_type'] = method['return_type'].strip()\n",
    "            sub_method['parameters'] = method['parameters'].strip()\n",
    "            sub_method['signature'] = method['signature'].strip()\n",
    "            sub_method['signature_no_mod'] = method['signature_no_mod'].strip()\n",
    "\n",
    "            res.append(sub_method)\n",
    "\n",
    "        return res\n",
    "\n",
    "    normalized_start = normalize_methods(methods_start)\n",
    "    normalized_end = normalize_methods(methods_end)\n",
    "    # normalized_start = [{key: method[key].strip() if isinstance(method[key], str) else method[key] for key in method} for method in methods_start]\n",
    "    # normalized_end = [{key: method[key].strip() if isinstance(method[key], str) else method[key] for key in method} for method in methods_end]\n",
    "\n",
    "    # Convert lists of methods to sets of frozensets for comparison\n",
    "    set_start = set(frozenset(item.items()) for item in normalized_start)\n",
    "    set_end = set(frozenset(item.items()) for item in normalized_end)\n",
    "\n",
    "    # Determine differences\n",
    "    removed_methods = [dict(items) for items in (set_start - set_end)]  # Methods in start but not in end\n",
    "    added_methods = [dict(items) for items in (set_end - set_start)]    # Methods in end but not in start\n",
    "    unchanged_methods = [dict(items) for items in (set_start & set_end)]  # Methods in both\n",
    "\n",
    "    return {\n",
    "        'removed': removed_methods,\n",
    "        'added': added_methods,\n",
    "        'unchanged': unchanged_methods,\n",
    "    }\n",
    "\n",
    "def check_same_methods(method1, method2):\n",
    "    '''\n",
    "    Check if two methods are the same based on their full dictionaries.\n",
    "    '''\n",
    "    return method1['signature_no_mod'] == method2['signature_no_mod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_(Class<? extends SubView> cls) {\n",
      "Loi : Parsing errors found in the code\n",
      "_(Class<? extends SubView> cls) {\n",
      "Loi : Parsing errors found in the code\n"
     ]
    }
   ],
   "source": [
    "for id in range(len(data_df)):\n",
    "    # if (id != 8219):\n",
    "    #     continue\n",
    "\n",
    "    id = 8219\n",
    "    sample = data_df.iloc[id]\n",
    "\n",
    "    start_code = sample['startCode']\n",
    "    end_code = sample['endCode']\n",
    "\n",
    "    with open('before.txt', 'w') as f:\n",
    "        f.write(start_code)\n",
    "    with open('after.txt', 'w') as f:\n",
    "        f.write(end_code)\n",
    "\n",
    "    start_code_cleaned = remove_comments(start_code)\n",
    "    end_code_cleaned = remove_comments(end_code)\n",
    "\n",
    "    with open('before_no_comment.txt', 'w') as f:\n",
    "        f.write(start_code_cleaned)\n",
    "    with open('after_no_comment.txt', 'w') as f:\n",
    "        f.write(end_code_cleaned)\n",
    "\n",
    "    # with open('before.txt', 'w') as f:\n",
    "    #     f.write(start_code)\n",
    "\n",
    "    # print(start_code)\n",
    "\n",
    "    method_start = extract_methods_with_body(start_code)\n",
    "    method_end = extract_methods_with_body(end_code)\n",
    "\n",
    "    # print(method_start)\n",
    "    # print(method_end)\n",
    "\n",
    "    # print(len(method_start))\n",
    "    # print(len(method_end))\n",
    "\n",
    "    break\n",
    "\n",
    "# start_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
